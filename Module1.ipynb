{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2ffa50-1a7d-40b2-be99-136437e197fa",
   "metadata": {},
   "source": [
    "# Module 1 - Extracting Gaussian features from input data\n",
    "*Updated on 2025-06-25*\n",
    "\n",
    "This Module is divided into five steps, taking input data, normalizing it, extracting Gaussian features from input data, reconstructing data by using Gaussian features and finally, determine the separation point of the two isomers.\n",
    "\n",
    "Users will be asked to navigate to the directory where the input data files are stored. Output excel files and plots will be stored in this same folder.\n",
    "\n",
    "The output excel files are: **CombinedAnalysis.xlsx, meanAllsigma.xlsx, Intersected gauss.xlsx** .\n",
    "The output plots are stored in folders: **RawPlots, NormalizedPlots, Gal_GaussianPlots, Glc_GaussianPlots, GaussianIntersectPlots** ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9be1eb0-4bf1-48a4-bc68-6c46e51b6357",
   "metadata": {},
   "source": [
    "## INSTALLATION OF IMPORTANT LIBRARIES AND PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f3dea-6377-40d5-8560-515180e44d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Import basic system parameters and functions\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "\n",
    "# Several packages needed to be installed. We first will check to see if your environment has already had these packages installed.\n",
    "required = {'pandas', 'seaborn', 'numpy', 'csaps', 'tensorflow', 'openpyxl', 'lmfit', 'tqdm'}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "\n",
    "if missing:\n",
    "    python = sys.executable\n",
    "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout = subprocess.DEVNULL)\n",
    "\n",
    "# After checking, we now will import from the installed packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pylab as plb\n",
    "import matplotlib.pyplot as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import mlab\n",
    "import numpy as np\n",
    "import heapq\n",
    "import csaps\n",
    "import shutil\n",
    "import time\n",
    "import tkinter\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from csaps import csaps\n",
    "from random import seed\n",
    "from random import choice\n",
    "from numpy import asarray as ar\n",
    "from numpy import exp, linspace, random, pi, sqrt\n",
    "from scipy import stats\n",
    "from scipy import interpolate\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import linregress\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import tensorflow as tn\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from lmfit import Model, conf_interval, report_ci\n",
    "from lmfit.models import ExpressionModel\n",
    "\n",
    "# Set Directory Location\n",
    "currentpath = os.getcwd()\n",
    "os.chdir(currentpath)\n",
    "\n",
    "# Set up folder for outputs and plots\n",
    "\n",
    "M1_RawPlots = './Module1_Outputs/Plots/RawPlots'\n",
    "M1_NormPlots = './Module1_Outputs/Plots/NormalizedPlots'\n",
    "M1_Gal_GaussPlots = './Module1_Outputs/Plots/Gal_GaussianPlots'\n",
    "M1_Glc_GaussPlots = './Module1_Outputs/Plots/Glc_GaussianPlots'\n",
    "M1_Intersect_GaussPlots = './Module1_Outputs/Plots/GaussianIntersectPlots'\n",
    "\n",
    "\n",
    "if not os.path.exists(M1_RawPlots):\n",
    "    os.makedirs(os.path.join('Module1_Outputs', 'Plots', 'RawPlots'))\n",
    "    os.chmod(M1_RawPlots,0o666)\n",
    "else:\n",
    "    os.chmod(M1_RawPlots,0o666)\n",
    "    shutil.rmtree(M1_RawPlots)\n",
    "    os.makedirs(os.path.join('Module1_Outputs', 'Plots', 'RawPlots'))\n",
    "    \n",
    "if not os.path.exists(M1_NormPlots):\n",
    "    os.makedirs(os.path.join('Module1_Outputs', 'Plots', 'NormalizedPlots'))\n",
    "    os.chmod(M1_NormPlots,0o666)\n",
    "else:\n",
    "    os.chmod(M1_NormPlots,0o666)\n",
    "    shutil.rmtree(M1_NormPlots)\n",
    "    os.makedirs(os.path.join('Module1_Outputs', 'Plots', 'NormalizedPlots'))\n",
    "\n",
    "if not os.path.exists(M1_Gal_GaussPlots):\n",
    "    os.makedirs(os.path.join('Module1_Outputs', 'Plots', 'Gal_GaussianPlots'))\n",
    "    os.chmod(M1_Gal_GaussPlots,0o666)\n",
    "else:\n",
    "    os.chmod(M1_Gal_GaussPlots,0o666)\n",
    "    shutil.rmtree(M1_Gal_GaussPlots)\n",
    "    os.makedirs(os.path.join('Module1_Outputs', 'Plots', 'Gal_GaussianPlots'))\n",
    "\n",
    "if not os.path.exists(M1_Glc_GaussPlots):\n",
    "    os.makedirs(os.path.join('Module1_Outputs', 'Plots', 'Glc_GaussianPlots'))\n",
    "    os.chmod(M1_Glc_GaussPlots,0o666)\n",
    "else:\n",
    "    os.chmod(M1_Glc_GaussPlots,0o666)\n",
    "    shutil.rmtree(M1_Glc_GaussPlots)\n",
    "    os.makedirs(os.path.join('Module1_Outputs', 'Plots', 'Glc_GaussianPlots'))\n",
    "\n",
    "if not os.path.exists(M1_Intersect_GaussPlots):\n",
    "    os.makedirs(os.path.join('Module1_Outputs', 'Plots', 'GaussianIntersectPlots'))\n",
    "    os.chmod(M1_Intersect_GaussPlots,0o666)\n",
    "else:\n",
    "    os.chmod(M1_Intersect_GaussPlots,0o666)\n",
    "    shutil.rmtree(M1_Intersect_GaussPlots)\n",
    "    os.makedirs(os.path.join('Module1_Outputs', 'Plots', 'GaussianIntersectPlots'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d73d505-f0a1-4dc1-8d85-e8aa9aa53f19",
   "metadata": {},
   "source": [
    "## STEP 1. Obtain empirical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f20628-e53b-40e4-af6c-89faded8dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browse to file location\n",
    "root = tkinter.Tk()\n",
    "InputDir = filedialog.askdirectory(parent= root,\n",
    "                                    initialdir=\"/\",\n",
    "                                    title = \"Browse to where files are stored\")\n",
    "if len(InputDir) > 0:\n",
    "    print (\"You chose %s\" % InputDir)\n",
    "\n",
    "root.withdraw() #use to hide tkinter window ; this line is important to prevent tkinter from hanging\n",
    "root.update()\n",
    "\n",
    "# Select the files for each isomer.\n",
    "## Files are read and stored as DataFrame.\n",
    "InputFile1 = filedialog.askopenfile(parent=root,\n",
    "                                   mode = 'rb',\n",
    "                                   title = \"Upload training data for Glucosyl Ceramide stereoisomers.\")\n",
    "if InputFile1 != None:\n",
    "    Glcsingle = pd.read_excel(InputFile1)\n",
    "\n",
    "root.withdraw()\n",
    "\n",
    "InputFile2 = filedialog.askopenfile(parent=root,\n",
    "                                   mode = 'rb',\n",
    "                                   title = \"Upload training data for Galactosyl Ceramide stereoisomers.\")\n",
    "if InputFile2 != None:\n",
    "    Galsingle = pd.read_excel(InputFile2)\n",
    "    \n",
    "root.withdraw()\n",
    "root.update()\n",
    "\n",
    "# Reformat the above files to round CoV to 1 decimals\n",
    "Galsingle['COV']=Galsingle['COV'].round(1)\n",
    "Glcsingle['COV']=Glcsingle['COV'].round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26da7de-727b-40f4-8a1c-765fa0b25bbd",
   "metadata": {},
   "source": [
    "## STEP 2. Checking empirical data and extracting important parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d691b11-6831-4ba5-b35a-82c4e63e78ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: SV range may not be the same for all isomers because a well-resolved peak may not be produced at all SV, which then would be excluded in QC step.\n",
    "\n",
    "# i) The number of unique lipid species in the input files must equal one another.\n",
    "nGlc = len(pd.unique(Glcsingle['Lipid Species']))\n",
    "Glc_unique = set(Glcsingle['Lipid Species'])\n",
    "print(\"Number of unique Glc species are\", nGlc, \"; and they are \", Glc_unique)\n",
    "\n",
    "nGal = len(pd.unique(Galsingle['Lipid Species']))\n",
    "Gal_unique = set(Galsingle['Lipid Species'])\n",
    "print(\"Number of unique Gal species are\", nGal, \"; and they are \", Gal_unique)\n",
    "\n",
    "# In this step, the code will check that the number of unique Glc species does equal the number of Gal species.\n",
    "# If they equal each other, code will continue.\n",
    "# If not, code will stop. User is asked to check their input dataset before retrying the code.\n",
    "if (nGlc == nGal):\n",
    "    nLipids = nGlc\n",
    "    list_Lipids = Glc_unique\n",
    "    print(\"The number of unique Glc isomer equals the number of unique Gal isomer. We will proceed!\")\n",
    "else:\n",
    "    print(\"The number of Glc lipid species DOES NOT MATCH the number of Gal lipid species. Algorithm cannot be built!\")\n",
    "    print(input(\"We will now exit the code. Please check your input datafiles, and restart the code with the correct input files. Type 'EXIT' \"))\n",
    "    exit()\n",
    "    \n",
    "# ii. Determine the number of replicates in dataset. The number of replicates in both isomers datafiles must match.\n",
    "if ((Glcsingle['replicateNum'].max()) == Galsingle['replicateNum'].max()):\n",
    "    nRep = Glcsingle['replicateNum'].max()\n",
    "    print(\"The number of experimental replicates for each Glc and for each Gal isomer is\", nRep)\n",
    "    print(\"Since they equal each other, we will proceed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"The number of experiment replicates for Glc lipid species DOES NOT MATCH that for Gal lipid species. Algorithm cannot be built!\")\n",
    "    print(input(\"We will now exit the code. Please check your input datafiles, and restart the code with the correct input files. Type 'EXIT' \"))\n",
    "    exit()\n",
    "\n",
    "# iii. Determine the CoV range used in input dataset. This COV range must be the same for every species, isomer, at all measured SV.\n",
    "if( (float(Glcsingle['COV'].min()) == float(Galsingle['COV'].min())) and (float(Glcsingle['COV'].max()) == float(Galsingle['COV'].max())) ):\n",
    "    minCoV = float(Glcsingle['COV'].min())\n",
    "    maxCoV = float(Galsingle['COV'].max())\n",
    "    stepCoV = float((maxCoV - minCoV) / ((Glcsingle['COV'].nunique())-1))\n",
    "    CoVList = pd.unique(Glcsingle['COV'])\n",
    "    print(\"The range of COV in this dataset is from \", minCoV, \" to \", maxCoV, \" with step of \", stepCoV, \" V for both isomers.\" )\n",
    "    print(\"Since the range matches, we will proceed!\")\n",
    "\n",
    "else:\n",
    "    print(\"We have a problem. The CoV range in this experiment is not the same for both isomers.\")\n",
    "    print(input(\"We will now exit the code. Please check your input datafiles, and restart the code with the correct input files. You may need to perform another optimization experiment with matching CoV range. Type 'EXIT' \"))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29596f9d-deea-4168-9347-a3dd9c88ac51",
   "metadata": {},
   "source": [
    "## STEP 3. Assess the original data, normalize and create ionogram plots of Glc and Gal isomer together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0fcc63-b245-43e2-85fe-98a650ab7d61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# i. A dictionary is created for all dataframes generarated for each lipid species for each isomer.\n",
    "dataGlc = {}\n",
    "for x in Glc_unique:\n",
    "    dataGlc[x] = pd.DataFrame()\n",
    "    dataGlc[x] = Glcsingle.loc[Glcsingle['Lipid Species'] == x]\n",
    "\n",
    "    \n",
    "dataGal = {}\n",
    "for x in Gal_unique:\n",
    "    dataGal[x] = pd.DataFrame()\n",
    "    dataGal[x] = Galsingle.loc[Galsingle['Lipid Species'] == x]\n",
    "    \n",
    "keys_dataGlc = list(dataGlc.keys())\n",
    "keys_dataGal = list(dataGal.keys())\n",
    "\n",
    "# ii. Normalize the raw data of each isomer by the maximum intensity at each SV. Then plot the normalized data.\n",
    "raw_GlcPeakCoV = pd.DataFrame()\n",
    "raw_GalPeakCoV = pd.DataFrame()\n",
    "norm_rawGlc = pd.DataFrame()\n",
    "norm_rawGal = pd.DataFrame()\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "for i in range(len(list_Lipids)):\n",
    "        Galtemp = Galsingle[Galsingle['Lipid Species']==keys_dataGal[i]]\n",
    "        Glctemp = Glcsingle[Glcsingle['Lipid Species']==keys_dataGlc[i]]\n",
    "        titleGal = 'GalCer(d18:1/' + str(keys_dataGal[i]) + ')'\n",
    "        titleGlc = 'GlcCer(d18:1/' + str(keys_dataGlc[i]) + ')'\n",
    "    \n",
    "        minSV = Galtemp['SV'].min()\n",
    "        maxSV = Galtemp['SV'].max()\n",
    "        stepSV = int((maxSV - minSV) / ((Galtemp['SV'].nunique())-1))         \n",
    "        \n",
    "        for duplicate in range(1, nRep+1):\n",
    "            for SV in range(minSV, (maxSV + stepSV), stepSV):\n",
    "                GaltempSV = Galtemp[(Galtemp['SV']==SV)&(Galtemp['replicateNum']==duplicate)]\n",
    "                GlctempSV = Glctemp[(Glctemp['SV']==SV)&(Glctemp['replicateNum']==duplicate)]\n",
    "                if (GaltempSV['Intensity'].max()) != 0 and (GaltempSV['Intensity'].max()) > 100 : # Intensity Criteria\n",
    "                    raw_GaltempPeakCoV = GaltempSV.loc[GaltempSV['Intensity']==GaltempSV['Intensity'].max()]\n",
    "                    raw_GalPeakCoV = pd.concat([raw_GalPeakCoV, raw_GaltempPeakCoV])\n",
    "                    raw_GalPeakCoV.reset_index(drop = True, inplace = True)\n",
    "                    \n",
    "                if (GlctempSV['Intensity'].max()) != 0 and (GlctempSV['Intensity'].max()) > 100 : # Intensity Criteria\n",
    "                    raw_GlctempPeakCoV = GlctempSV.loc[GlctempSV['Intensity']==GlctempSV['Intensity'].max()]\n",
    "                    raw_GlcPeakCoV = pd.concat([raw_GlcPeakCoV, raw_GlctempPeakCoV])\n",
    "                    raw_GlcPeakCoV.reset_index(drop = True, inplace = True)\n",
    "                    \n",
    "                raw_GalPeakCoV.sort_values(by = ['Lipid Species', 'SV'], ascending=[True, True], inplace=True, \n",
    "                                           na_position='first', ignore_index=True, key=None)\n",
    "                \n",
    "                raw_GlcPeakCoV.sort_values(by = ['Lipid Species', 'SV'], ascending=[True, True], inplace=True,\n",
    "                                           na_position='first', ignore_index=True, key=None)                \n",
    "                \n",
    "                # Plot raw data\n",
    "                ## Glc first\n",
    "                plt.figure()\n",
    "                plt.plot(GlctempSV['COV'],GlctempSV['Intensity'], 'o', color='grey', linewidth=1)\n",
    "                plt.ylabel('Signal Intensity', fontsize = 12)\n",
    "                plt.xlabel('CoV', fontsize = 12)\n",
    "                plt.title((titleGlc +' at '+'SV '+str(SV) + ' ' + 'Rep ' + str(duplicate)), fontsize = 14)\n",
    "                #plt.legend([\"Signal Intensity\"])\n",
    "                temp_Glc = plt.gcf()\n",
    "                plt.show()\n",
    "                plt.draw()\n",
    "                plotname = 'Glc' + keys_dataGlc[i] + '_SV' + str(SV) + '_rep' + str(duplicate)\n",
    "                plotname = plotname.replace(\":\",\"-\")\n",
    "                plotpath = os.path.join(currentpath, M1_RawPlots,plotname)\n",
    "                temp_Glc.savefig(plotpath)\n",
    "                \n",
    "                \n",
    "                ## Gal\n",
    "                plt.plot(GaltempSV['COV'],GaltempSV['Intensity'], 'o', color='grey', linewidth=1)\n",
    "                plt.ylabel('Signal Intensity', fontsize = 12)\n",
    "                plt.xlabel('CoV', fontsize = 12)\n",
    "                plt.title((titleGal +' at '+'SV '+str(SV) + ' ' + 'Rep ' + str(duplicate)), fontsize = 14)\n",
    "                #plt.legend([\"Signal Intensity\"])\n",
    "                temp_Gal = plt.gcf()\n",
    "                plt.show()\n",
    "                plt.draw()\n",
    "                plotname = 'Gal' + keys_dataGal[i] + '_SV' + str(SV) + '_rep' + str(duplicate)\n",
    "                plotname = plotname.replace(\":\",\"-\")\n",
    "                plotpath = os.path.join(currentpath, M1_RawPlots,plotname)\n",
    "                temp_Gal.savefig(plotpath)\n",
    "               \n",
    "                          \n",
    "                #Normalize the raw data\n",
    "                GaltempSV['NormPeakIntensity'] = GaltempSV[\"Intensity\"]/GaltempSV[\"Intensity\"].max()\n",
    "                norm_rawGal = pd.concat([norm_rawGal, GaltempSV])\n",
    "                norm_rawGal.reset_index(drop = True, inplace = True)\n",
    "                \n",
    "                GlctempSV['NormPeakIntensity'] = GlctempSV[\"Intensity\"]/GlctempSV[\"Intensity\"].max()\n",
    "                norm_rawGlc = pd.concat([norm_rawGlc, GlctempSV])\n",
    "                norm_rawGlc.reset_index(drop = True, inplace = True)\n",
    "                \n",
    "                # Plot normalized data\n",
    "                ## Glc first\n",
    "                plt.plot(GlctempSV['COV'],GlctempSV['NormPeakIntensity'], 'o', color='grey', linewidth=1)\n",
    "                plt.plot(GlctempSV['COV'],GlctempSV['NormPeakIntensity'],color='grey',label='GlcCer' )\n",
    "                plt.ylabel('Normalized  Signal Intensity', fontsize = 12)\n",
    "                plt.xlabel('CoV', fontsize = 12) \n",
    "                plt.title((titleGlc +' at '+'SV '+str(SV) + ' ' + 'Rep ' + str(duplicate)), fontsize = 14)\n",
    "                plt.legend([\"Normalized\\nSignal\"])\n",
    "                temp_Glc = plt.gcf()\n",
    "                plt.show()\n",
    "                plt.draw()\n",
    "                plotname = 'Glc' + keys_dataGal[i] + '_SV' + str(SV) + '_rep' + str(duplicate)\n",
    "                plotname = plotname.replace(\":\",\"-\")\n",
    "                plotpath = os.path.join(currentpath, M1_NormPlots, plotname)\n",
    "                temp_Glc.savefig(plotpath)\n",
    "\n",
    "                \n",
    "                ## Gal\n",
    "                plt.plot(GaltempSV['COV'],GaltempSV['NormPeakIntensity'], 'o', color='grey', linewidth=1)\n",
    "                plt.plot(GaltempSV['COV'],GaltempSV['NormPeakIntensity'],color='grey',label='GalCer')\n",
    "                plt.ylabel('Normalized Signal Intensity', fontsize = 12)\n",
    "                plt.xlabel('CoV', fontsize = 12) \n",
    "                plt.title((titleGal +' at '+'SV '+str(SV) + ' ' + 'Rep ' + str(duplicate)), fontsize = 14)\n",
    "                plt.legend([\"Normalized\\nSignal\"])\n",
    "                temp_Gal = plt.gcf()\n",
    "                plt.show()\n",
    "                plt.draw()\n",
    "                plotname = 'Gal' + keys_dataGal[i] + '_SV' + str(SV) + '_rep' + str(duplicate)\n",
    "                plotname = plotname.replace(\":\",\"-\")\n",
    "                plotpath = os.path.join(currentpath, M1_NormPlots, plotname)\n",
    "                temp_Gal.savefig(plotpath)\n",
    "                \n",
    "    \n",
    "plt.close()\n",
    "\n",
    "# Output raw CoV files for checking\n",
    "raw_GalPeakCoV.to_excel('Module1_Outputs/raw_GalPeakCoV.xlsx')\n",
    "raw_GlcPeakCoV.to_excel('Module1_Outputs/raw_GlcPeakCoV.xlsx')\n",
    "\n",
    "# Output normalized raw datafiles for checking\n",
    "norm_rawGal.to_excel('Module1_Outputs/norm_rawGal.xlsx')\n",
    "norm_rawGlc.to_excel('Module1_Outputs/norm_rawGlc.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c272b-6729-4530-bf27-1d121f7dd9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message to users\n",
    "print(\"All plots from normalized input data are saved in folder called 'NormalizedPlots.' \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96730951-45a1-4cbf-a06e-d7bb211a1e24",
   "metadata": {},
   "source": [
    "## STEP 4. Gaussian fit the normalized data, then obtain gaussian features (sigma and mu) from the fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6331bc-8659-43fe-abb4-33f8952e49a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# i. Gaussian fit to normalized data. As well, extract Gaussian features for each replicate at each SV.\n",
    "\n",
    "norm_GalPeakFeatures = pd.DataFrame()\n",
    "norm_GlcPeakFeatures = pd.DataFrame()\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "plt.close()\n",
    "lipid_isomer = [\"Gal\", \"Glc\"]\n",
    "\n",
    "## Define Gaussian function\n",
    "def gaussian(x, mu, sigma):\n",
    "   y = 1 * exp(-0.5*((x-mu)/sigma)**2)\n",
    "   return y\n",
    "\n",
    "## Looping to derive function and features from data\n",
    "\n",
    "for isomer in lipid_isomer:\n",
    "    if isomer == \"Gal\":\n",
    "        for i in range(len(list_Lipids)):\n",
    "            Galtemp = (norm_rawGal[norm_rawGal['Lipid Species']==keys_dataGal[i]]).dropna()        \n",
    "            Galtempmu = raw_GalPeakCoV[raw_GalPeakCoV['Lipid Species']==keys_dataGal[i]]\n",
    "            \n",
    "            minSV_Gal = Galtemp['SV'].min()\n",
    "            maxSV_Gal = Galtemp['SV'].max()            \n",
    "            stepSV = int((maxSV_Gal - minSV_Gal) / ((Galtemp['SV'].nunique())-1))\n",
    "            \n",
    "            for duplicate in range(1, nRep+1):\n",
    "                Gal_rep = Galtemp[Galtemp['replicateNum']==duplicate]\n",
    "                Gal_mu_rep = Galtempmu[Galtempmu['replicateNum']==duplicate]\n",
    "                \n",
    "                for SV in range(minSV_Gal, maxSV_Gal+stepSV, stepSV):\n",
    "                    GaltempSV = Gal_rep[(Gal_rep['SV']==SV)]\n",
    "                    GaltempmuSV = Gal_mu_rep[(Gal_mu_rep['SV']==SV)]\n",
    "                    \n",
    "                    xGaldata = ar(GaltempSV[\"COV\"])\n",
    "                    yGaldata = ar(GaltempSV[\"NormPeakIntensity\"])\n",
    "                    mu_Gal = float(sum(GaltempmuSV['COV'])/(GaltempmuSV.shape[0])) #this will be the start point\n",
    "                    \n",
    "                    # Use Model fit to fit data. Here we use Lmfit to build a Model wrapping the gaussian model function\n",
    "                    # We assign initial values for this model with mu as the average mu across all CoV for a specific SV (peakCoV)\n",
    "                    # and sigma at 1.\n",
    "                    # As well, here, we use method 'fit' of the model to fit data to this model with the initial parameters\n",
    "                    gmodel = Model(gaussian)\n",
    "                    Gal_result = gmodel.fit(yGaldata, x=xGaldata, mu = mu_Gal, sigma = 1)\n",
    "                    Gal_uncertain = Gal_result.eval_uncertainty(sigma = 3)\n",
    "\n",
    "                    # Modified parameters set 1 for less optimal fit_FOR GAL\n",
    "                    modified_Gal_params1 = Gal_result.init_params.copy()\n",
    "                    modified_Gal_params1['mu'].value = mu_Gal\n",
    "                    modified_Gal_params1['sigma'].value = 0.75\n",
    "                    \n",
    "                    # Calculate new model 1 with modified parameters set 1_FOR GAL\n",
    "                    y_Gal_modified1 = gmodel.eval(modified_Gal_params1, x=xGaldata)\n",
    "                    \n",
    "                    # Modified parameters set 2 for less optimal fit_FOR GAL\n",
    "                    modified_Gal_params2 = Gal_result.init_params.copy()\n",
    "                    modified_Gal_params2['mu'].value = mu_Gal\n",
    "                    modified_Gal_params2['sigma'].value = 0.25\n",
    "                    \n",
    "                    # Calculate new model 2 with modified parameters set 2_FOR GAL\n",
    "                    y_Gal_modified2 = gmodel.eval(modified_Gal_params2, x=xGaldata)\n",
    "                    \n",
    "                    # The ModelResult methods provide fit parameters and results from the model. We use 'summary' method\n",
    "                    # to output the statistics and attributes of the model's results. This is a dictionary.\n",
    "                    # We then derive the value for key \"best_values\" from the summary, which are mu and sigma\n",
    "                    gmodel_report = Gal_result.fit_report()\n",
    "                    gmodel_summary = Gal_result.summary()\n",
    "                    bestfit_features = gmodel_summary[\"best_values\"]\n",
    "                    bestfit_features_list = list(bestfit_features.values())\n",
    "                    r_squared = gmodel_summary[\"rsquared\"]\n",
    "                    \n",
    "                    \n",
    "                    # The best fit values are now derived from feature list above and assigned to mu, sigma\n",
    "                    Gal_fit_mu = bestfit_features_list[0]\n",
    "                    Gal_fit_sigma = bestfit_features_list[1]\n",
    "                    \n",
    "                    # Now, we will use method 'eval' to evalute our model function. Here, we will calculate\n",
    "                    # confidence interval of the fitted variable parameters, determine the uncertainties of our model,\n",
    "                    # and plot the uncertainties as number of sigma away from the fit parameters\n",
    "                    \n",
    "                    # a) Confidence interval: Use F-test method. The optimized/fit parameters are compared to a specific value.\n",
    "                    # Read: lmfit.github.io/lmfit-py/confidence.html#confidence-chapter\n",
    "                    # b) Uncertainty: Calculate the uncertainties of the fitted parameters. This means, given a specific value\n",
    "                    # of sigma away from the fitted parameters, what are the predicted y values. We get to see how far the\n",
    "                    # predictions are from the actual data, and the fitted curve.\n",
    "                    ci = Gal_result.conf_interval()\n",
    "                    \n",
    "                    \n",
    "                                       \n",
    "                    # Compile Peak Features for Gal\n",
    "                    GaltempmuSV['NormPeakIntensity'] = yGaldata.max()\n",
    "                    GaltempmuSV['Empirical mu'] = mu_Gal\n",
    "                    GaltempmuSV['Gal_Gaussian_mu'] = Gal_fit_mu\n",
    "                    GaltempmuSV['Gal_Gaussian_sigma'] = Gal_fit_sigma\n",
    "                    GaltempmuSV['Gal_Rsquared'] = r_squared\n",
    "                    norm_GalPeakFeatures = pd.concat([norm_GalPeakFeatures,GaltempmuSV])\n",
    "                    norm_GalPeakFeatures.reset_index(drop = True, inplace = True)\n",
    "                       \n",
    "                     # Plot fit over original data. We will display original data, initial fit with given initial \n",
    "                     # parameters and best fit values. \n",
    "\n",
    "                    plt.figure()\n",
    "                    titlelipid = 'GalCer(d18:1/' + str(keys_dataGal[i]) + ')'\n",
    "                    plt.ylabel('Normalized Signal Intensity')\n",
    "                    plt.xlabel('CoV')\n",
    "                    plt.title((titleGal +' at '+'SV '+str(SV) + ' ' + 'Rep ' + str(duplicate)), fontsize = 14)\n",
    "                    \n",
    "                    plt.plot(xGaldata, yGaldata, 'o', color='grey', label='Original Gal')\n",
    "                    plt.plot(xGaldata, Gal_result.init_fit, '--', color='darkorange', label='Initial fit')\n",
    "                    plt.plot(xGaldata, Gal_result.best_fit, '-', color='green', label='Best fit')\n",
    "                    plt.plot(xGaldata, y_Gal_modified1, '--', label='Less Optimal Fit 1', color = 'goldenrod')\n",
    "                    plt.plot(xGaldata, y_Gal_modified2, '--', label='Less Optimal Fit 2', color = 'gold')\n",
    "                    plt.legend()\n",
    "                    temp_Gal = plt.gcf()\n",
    "                    plt.show()\n",
    "                    plt.draw()\n",
    "                    plotname = isomer + keys_dataGal[i] + '_SV' + str(SV) + '_rep' + str(duplicate)\n",
    "                    plotname = plotname.replace(\":\",\"-\")\n",
    "                    plotpath = os.path.join(currentpath, M1_Gal_GaussPlots, plotname)\n",
    "                    temp_Gal.savefig(plotpath)\n",
    "                    \n",
    "                  \n",
    "                    \n",
    "    elif isomer == \"Glc\":\n",
    "        for i in range(len(list_Lipids)):\n",
    "            Glctemp = (norm_rawGlc[norm_rawGlc['Lipid Species']==keys_dataGlc[i]]).dropna()\n",
    "            Glctempmu = raw_GlcPeakCoV[raw_GlcPeakCoV['Lipid Species']==keys_dataGlc[i]]\n",
    "            \n",
    "            minSV_Glc = Glctemp['SV'].min()\n",
    "            maxSV_Glc = Glctemp['SV'].max()\n",
    "            stepSV = int((maxSV_Glc - minSV_Glc) / ((Glctemp['SV'].nunique())-1))\n",
    "            \n",
    "            for duplicate in range(1, nRep+1):\n",
    "                for SV in range(minSV_Glc, maxSV_Glc+stepSV, stepSV):\n",
    "                    GlctempSV = Glctemp[(Glctemp['SV']==SV)&(Glctemp['replicateNum']==duplicate)]\n",
    "                    GlctempmuSV = Glctempmu[(Glctempmu['SV']==SV) & (Glctempmu['replicateNum']==duplicate)]\n",
    "                    \n",
    "                    xGlcdata = ar(GlctempSV[\"COV\"])\n",
    "                    yGlcdata = ar(GlctempSV[\"NormPeakIntensity\"])\n",
    "                    mu_Glc = float(sum(GlctempmuSV['COV'])/(GlctempmuSV.shape[0])) #this will be the start point\n",
    "                    \n",
    "                    # Use Model fit to fit data. Here we use Lmfit to build a Model wrapping the gaussian model function\n",
    "                    # We assign initial values for this model with mu as the average mu across all CoV for a specific SV (peakCoV)\n",
    "                    # and sigma at 1.\n",
    "                    # As well, here, we use method 'fit' of the model to fit data to this model with the initial parameters\n",
    "                    gmodel = Model(gaussian)\n",
    "                    Glc_result = gmodel.fit(yGlcdata, x=xGlcdata, mu = mu_Glc, sigma = 1)\n",
    "                    \n",
    "                    \n",
    "                    # Modified parameters set 1 for less optimal fit_FOR GLC\n",
    "                    modified_Glc_params1 = Glc_result.init_params.copy()\n",
    "                    modified_Glc_params1['mu'].value = mu_Glc\n",
    "                    modified_Glc_params1['sigma'].value = 0.75\n",
    "                    \n",
    "                    # Calculate new model 1 with modified parameters set 1_FOR GLC\n",
    "                    y_Glc_modified1 = gmodel.eval(modified_Glc_params1, x=xGlcdata)\n",
    "                    \n",
    "                    # Modified parameters set 2 for less optimal fit_FOR GLC\n",
    "                    modified_Glc_params2 = Glc_result.init_params.copy()\n",
    "                    modified_Glc_params2['mu'].value = mu_Glc\n",
    "                    modified_Glc_params2['sigma'].value = 0.25\n",
    "                    \n",
    "                    # Calculate new model 2 with modified parameters set 2_FOR GLC\n",
    "                    y_Glc_modified2 = gmodel.eval(modified_Glc_params2, x=xGlcdata)\n",
    "                    \n",
    "                    # The ModelResult methods provide fit parameters and results from the model. We use 'summary' method\n",
    "                    # to output the statistics and attributes of the model's results. This is a dictionary.\n",
    "                    # We then derive the value for key \"best_values\" from the summary, which are mu and sigma\n",
    "                    gmodel_report = Glc_result.fit_report()\n",
    "                    gmodel_summary = Glc_result.summary()\n",
    "                    bestfit_features = gmodel_summary[\"best_values\"]\n",
    "                    bestfit_features_list = list(bestfit_features.values())\n",
    "                    r_squared = gmodel_summary[\"rsquared\"]\n",
    "                    \n",
    "                    \n",
    "                    # The best fit values are now derived from feature list above and assigned to mu, sigma\n",
    "                    Glc_fit_mu = bestfit_features_list[0]\n",
    "                    Glc_fit_sigma = bestfit_features_list[1]\n",
    "                    \n",
    "                    # Now, we will use method 'eval' to evalute our model function. Here, we will calculate\n",
    "                    # confidence interval of the fitted variable parameters, determine the uncertainties of our model,\n",
    "                    # and plot the uncertainties as number of sigma away from the fit parameters\n",
    "                    \n",
    "                    # a) Confidence interval: Use F-test method. The optimized/fit parameters are compared to a specific value.\n",
    "                    # Read: lmfit.github.io/lmfit-py/confidence.html#confidence-chapter\n",
    "                    # b) Uncertainty: Calculate the uncertainties of the fitted parameters. This means, given a specific value\n",
    "                    # of sigma away from the fitted parameters, what are the predicted y values. We get to see how far the\n",
    "                    # predictions are from the actual data, and the fitted curve.\n",
    "                    ci = Glc_result.conf_interval()\n",
    "                    Glc_uncertain = Glc_result.eval_uncertainty(sigma = 3)\n",
    "                                       \n",
    "                                       \n",
    "                    # Compile Peak Features for Glc\n",
    "                    GlctempmuSV['NormPeakIntensity'] = yGlcdata.max()\n",
    "                    GlctempmuSV['Empirical mu'] = mu_Glc\n",
    "                    GlctempmuSV['Glc_Gaussian_mu'] = Glc_fit_mu\n",
    "                    GlctempmuSV['Glc_Gaussian_sigma'] = Glc_fit_sigma\n",
    "                    GlctempmuSV['Glc_Rsquared'] = r_squared\n",
    "                    norm_GlcPeakFeatures = pd.concat([norm_GlcPeakFeatures,GlctempmuSV])\n",
    "                    norm_GlcPeakFeatures.reset_index(drop = True, inplace = True)\n",
    "                       \n",
    "                    # Plot fit over original data. We will display original data, initial fit with given initial \n",
    "                    # parameters and best fit values. \n",
    "                     \n",
    "                    plt.figure()\n",
    "                    titlelipid = 'GlcCer(d18:1/' + str(keys_dataGlc[i]) + ')'\n",
    "                    plt.ylabel('Normalized Scanned Intensity')\n",
    "                    plt.xlabel('CoV')\n",
    "                    plt.title((titleGlc +' at '+'SV '+str(SV) + ' ' + 'Rep ' + str(duplicate)), fontsize = 14)\n",
    "                    plt.plot(xGlcdata, yGlcdata, 'o', color='grey', label='Original Glc')\n",
    "                    plt.plot(xGlcdata, Glc_result.init_fit, '--', color='darkorange', label='Initial fit')\n",
    "                    plt.plot(xGlcdata, Glc_result.best_fit, '-', color='blue', label='Best fit')\n",
    "                    plt.plot(xGlcdata, y_Glc_modified1, '--', label='Less Optimal Fit 1', color = 'goldenrod')\n",
    "                    plt.plot(xGlcdata, y_Glc_modified2, '--', label='Less Optimal Fit 2', color = 'gold')\n",
    "                    plt.legend()\n",
    "                    temp_Glc = plt.gcf()\n",
    "                    plt.show()\n",
    "                    plt.draw()\n",
    "                    plotname = isomer + keys_dataGlc[i] + '_SV' + str(SV) + '_rep' + str(duplicate)\n",
    "                    plotname = plotname.replace(\":\",\"-\")\n",
    "                    plotpath = os.path.join(currentpath, M1_Glc_GaussPlots, plotname)\n",
    "                    temp_Glc.savefig(plotpath)\n",
    "plt.close()    \n",
    "\n",
    "## Output Gaussian files\n",
    "\n",
    "norm_GalPeakFeatures.to_excel('Module1_Outputs/norm_GalPeakFeatures.xlsx')\n",
    "norm_GlcPeakFeatures.to_excel('Module1_Outputs/norm_GlcPeakFeatures.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f3421-c7ca-4822-a49a-42bdfd666845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii. Averaged Gaussian features extraction from all replicates\n",
    "\n",
    "Galfeatures = pd.DataFrame()\n",
    "Galfeatures_combined = pd.DataFrame()\n",
    "Glcfeatures = pd.DataFrame()\n",
    "Glcfeatures_combined = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in range(len(list_Lipids)):\n",
    "    Galfeatures_temp = (norm_GalPeakFeatures[norm_GalPeakFeatures['Lipid Species']==keys_dataGal[i]])\n",
    "    Glcfeatures_temp = (norm_GlcPeakFeatures[norm_GlcPeakFeatures['Lipid Species']==keys_dataGlc[i]])\n",
    "    \n",
    "    minSV = Galfeatures_temp['SV'].min()\n",
    "    maxSV = Galfeatures_temp['SV'].max()\n",
    "    stepSV = int((maxSV - minSV) / ((Galfeatures_temp['SV'].nunique())-1))\n",
    "     \n",
    "    \n",
    "    for SV in range(minSV, maxSV+stepSV, stepSV):\n",
    "        GalfeaturesSV_temp = Galfeatures_temp[Galfeatures_temp['SV']==SV]\n",
    "        GlcfeaturesSV_temp = Glcfeatures_temp[Glcfeatures_temp['SV']==SV]\n",
    "        \n",
    "        cols = [\"Lipid Species\", \"SV\", \"chain length\", \"degree of unsaturation\"]\n",
    "        Galfeatures = GalfeaturesSV_temp[cols]\n",
    "        Galfeatures.drop_duplicates(inplace = True)\n",
    "        \n",
    "        Glcfeatures = GlcfeaturesSV_temp[cols]\n",
    "        Glcfeatures.drop_duplicates(inplace = True)\n",
    "        \n",
    "        \n",
    "        Galfeatures['mu_Gal'] =  GalfeaturesSV_temp.loc[:,'Gal_Gaussian_mu'].mean()\n",
    "        Galfeatures['sigma_Gal'] = GalfeaturesSV_temp.loc[:,'Gal_Gaussian_sigma'].mean()\n",
    "        Galfeatures['peakIntensity_at_mu_Gal'] = GalfeaturesSV_temp.loc[:,'Intensity'].mean()\n",
    "        \n",
    "        \n",
    "        Glcfeatures['mu_Glc'] =  GlcfeaturesSV_temp.loc[:,'Glc_Gaussian_mu'].mean()\n",
    "        Glcfeatures['sigma_Glc'] = GlcfeaturesSV_temp.loc[:,'Glc_Gaussian_sigma'].mean()\n",
    "        Glcfeatures['peakIntensity_at_mu_Glc'] = GlcfeaturesSV_temp.loc[:,'Intensity'].mean()\n",
    "        \n",
    "                \n",
    "        Galfeatures_combined = pd.concat([Galfeatures_combined, Galfeatures])\n",
    "        Glcfeatures_combined = pd.concat([Glcfeatures_combined, Glcfeatures])\n",
    "        \n",
    "        if Galfeatures_combined.shape[0] > Glcfeatures_combined.shape[0]:\n",
    "            CombinedAnalysis = pd.merge(Galfeatures_combined, Glcfeatures_combined, how = \"outer\", on = [\"Lipid Species\", \"SV\", \"chain length\", \"degree of unsaturation\"])\n",
    "            \n",
    "        else:\n",
    "            CombinedAnalysis = pd.merge(Glcfeatures_combined, Galfeatures_combined, how = \"outer\", on = [\"Lipid Species\", \"SV\", \"chain length\", \"degree of unsaturation\"])\n",
    "            \n",
    "        CombinedAnalysis.reset_index(drop = True, inplace = True)\n",
    "        CombinedAnalysis.drop(CombinedAnalysis.columns[CombinedAnalysis.columns.str.contains('unnamed', case=False)], axis = 1, inplace = True)\n",
    "              \n",
    "## Output Gaussian files\n",
    "CombinedAnalysis.to_excel('Module1_Outputs/CombinedAnalysis.xlsx')\n",
    "\n",
    "## Calculate average sigma across all lipids, at each SV\n",
    "\n",
    "meanAllsigma = CombinedAnalysis.groupby('SV').mean('sigma_Glc', 'sigma_Gal').reset_index()\n",
    "meanAllsigma.to_excel('Module1_Outputs/meanAllsigma.xlsx', columns =['SV','sigma_Glc', 'sigma_Gal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed2534e-d984-4147-8b7c-124398b2343a",
   "metadata": {},
   "source": [
    "## STEP 5. Find the intersection point of Glc and Gal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6253d589-fe31-4790-8d42-15ab4d082692",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Intersected_gauss = pd.DataFrame()\n",
    "\n",
    "def solve(mu_Gal,mu_Glc,sig_Gal,sig_Glc): \n",
    "  a = 1/(2*sig_Gal**2) - 1/(2*sig_Glc**2)\n",
    "  b = mu_Glc/(sig_Glc**2) - mu_Gal/(sig_Gal**2)\n",
    "  c = mu_Gal**2 /(2*sig_Gal**2) - mu_Glc**2 / (2*sig_Glc**2) - np.log(sig_Glc/sig_Gal)\n",
    "  return np.roots([a,b,c])\n",
    "\n",
    "for i in range(len(list_Lipids)):\n",
    "    intersect_temp = (CombinedAnalysis[CombinedAnalysis['Lipid Species']==keys_dataGal[i]])\n",
    "    \n",
    "    minSV = intersect_temp['SV'].min()\n",
    "    maxSV = intersect_temp['SV'].max()\n",
    "    stepSV = int((maxSV - minSV) / ((intersect_temp['SV'].nunique())-1))\n",
    "    \n",
    "       \n",
    "    for SV in range(minSV, maxSV+stepSV, stepSV):\n",
    "        intersectSV_temp = intersect_temp[intersect_temp['SV']==SV]\n",
    "        \n",
    "        if intersectSV_temp[\"mu_Gal\"].notna() is False:\n",
    "            continue\n",
    "        else:\n",
    "            mu_Gal = float(intersectSV_temp[\"mu_Gal\"])\n",
    "            sig_Gal = float(intersectSV_temp[\"sigma_Gal\"])\n",
    "        \n",
    "        if intersectSV_temp[\"mu_Glc\"].notna() is False:\n",
    "            continue\n",
    "        else:\n",
    "            mu_Glc = float(intersectSV_temp[\"mu_Glc\"])\n",
    "            sig_Glc = float(intersectSV_temp[\"sigma_Glc\"])\n",
    "        \n",
    "        gauss_features = [mu_Gal, mu_Glc, sig_Gal, sig_Glc] \n",
    "     \n",
    "        if any(pd.isna(gauss_features)) is True:\n",
    "            continue\n",
    "        else:\n",
    "            resultCombined = solve(mu_Gal, mu_Glc, sig_Gal, sig_Glc)\n",
    "        \n",
    "        \n",
    "        # Based on peak CoV, this step we predict the intensity by refitting X back to the gaussian function.\n",
    "        x = np.linspace(-10,10,10000) \n",
    "        y_Gal = gaussian(x, mu_Gal, sig_Gal)\n",
    "        y_Glc = gaussian(x, mu_Glc, sig_Glc)\n",
    "        \n",
    "        # Intersection point is limited to only that lies between mu of Glc and Gal\n",
    "        mu_range_max = max(mu_Glc, mu_Gal)\n",
    "        mu_range_min = min(mu_Glc, mu_Gal)\n",
    "        \n",
    "        intersect = max([point for point in resultCombined if mu_range_min < point < mu_range_max], default = \"NAN\")\n",
    "        \n",
    "        if type(intersect) is str:\n",
    "            y_at_intersect = intersect\n",
    "            \n",
    "        else:\n",
    "            #y_at_intersect = gaussian(intersect, mu_Gal, sig_Gal) # Result is different if Gal gaussian features are choosen to determine the intersected point.\n",
    "            y_at_intersect = gaussian(intersect, mu_Glc, sig_Glc) # We choose Glc here because it is the left limit.\n",
    "         \n",
    "        if intersect != \"NAN\" and (y_at_intersect < 0.5 ):              \n",
    "            intersectSV_temp[\"Valley CoV\"] = intersect # Valley is defined as separation\n",
    "\n",
    "        intersectSV_temp[\"Intersection point\"] = intersect\n",
    "        intersectSV_temp[\"Norm Intensity at Intersection\"] = y_at_intersect\n",
    "        \n",
    "        ax = []\n",
    "        ax = plt.gca()\n",
    "        ax.set_xlim([minCoV, maxCoV])\n",
    "\n",
    "        \n",
    "        titlelipid = 'Gaussian distribution plot based on averaged mu and sigma of \\n GlcCer(d18:1/' + str(keys_dataGal[i]) + ' and GalCer(d18:1/' + str(keys_dataGal[i]) + ') at SV ' + str(SV)\n",
    "        plt.ylabel('Normalized Signal Intensity')\n",
    "        plt.xlabel('CoV')\n",
    "        plt.title(titlelipid)\n",
    "        plot1 = plt.plot(x, y_Gal, color='green', label='GalCer(d18:1/' + str(keys_dataGal[i]))\n",
    "        plot2 = plt.plot(x, y_Glc, color='blue', label='GlcCer(d18:1/' + str(keys_dataGlc[i]))\n",
    "        \n",
    "        if intersect != \"NAN\":\n",
    "          plot3 = plt.plot(intersect, y_at_intersect, 'ro', fillstyle='none', label = 'Intersection point')\n",
    "          \n",
    "        plt.legend(loc='upper right')\n",
    "        temp_plot = plt.gcf()\n",
    "        plt.show()\n",
    "        plt.draw()\n",
    "        \n",
    "        plotname = 'GaussIntersected Glc' + keys_dataGal[i] + '_Gal' + keys_dataGlc[i] + '_SV' + str(SV) + '_rep' + str(duplicate)\n",
    "        plotname = plotname.replace(\":\",\"-\")\n",
    "        plotpath = os.path.join(currentpath, M1_Intersect_GaussPlots, plotname)\n",
    "        temp_plot.savefig(plotpath)\n",
    "       \n",
    "        Intersected_gauss = pd.concat([Intersected_gauss, intersectSV_temp])\n",
    "        Intersected_gauss.reset_index(drop = True, inplace = True)\n",
    "        \n",
    "# Binary Separation Column\n",
    "\n",
    "Intersected_gauss['Sep or InSep'] = np.where(Intersected_gauss['Valley CoV'].isnull(), \"Inseparable\", \"Separable\")\n",
    "        \n",
    "# Output intersection point to files\n",
    "\n",
    "Intersected_gauss = Intersected_gauss.replace('NAN','')\n",
    "Intersected_gauss.to_excel('Module1_Outputs/Intersected gauss.xlsx')\n",
    "\n",
    "#Intersected_gauss.to_excel('Intersected gauss_Glc.xlsx')\n",
    "\n",
    "# By this point, we have had all the features and data necessary to start performing 1) Training of a model, 2) Testing each model,\n",
    "# and 3) Pick a Model for prediction. We will write this in another set of script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe5f265-298f-40d0-a189-6e5e3feb9d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Please move on to the next module, either Module 2 or Module 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0600a5d6-9aa0-4530-8344-c17e85daf08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ead30d-5e9e-4092-94d0-6f82427f114a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702fd653-c1e2-4242-82ab-067f6a00f924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
